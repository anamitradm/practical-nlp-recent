{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO0xeC7LgjYjScivZd/2XQc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/axel-sirota/practical-nlp/blob/main/1-similarity/Practical_NLP_3_Doc2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZMSZTJFAflJf"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import smart_open\n",
        "import pandas as pd\n",
        "import gensim\n",
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "from gensim.test.utils import get_tmpfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "embedding_dim = 100\n",
        "vocabulary_size_to_use = 50000\n",
        "epochs = 10\n",
        "train_file_path = './train_yelp.csv'\n",
        "test_file_path = './test_yelp.csv'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile get_data.sh\n",
        "if [ ! -f yelp.csv ]; then\n",
        "  wget -O yelp.csv https://www.dropbox.com/s/xds4lua69b7okw8/yelp.csv?dl=0\n",
        "fi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhPGYNHngORV",
        "outputId": "32af3d27-84eb-46d5-8051-b59d4571dba9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting get_data.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash get_data.sh"
      ],
      "metadata": {
        "id": "OIkEglxYkHa4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = './yelp.csv'\n",
        "yelp = pd.read_csv(path)\n",
        "# Create a new DataFrame that only contains the 5-star and 1-star reviews.\n",
        "yelp_best_worst = yelp[(yelp.stars==5) | (yelp.stars==1)]\n",
        "X = yelp_best_worst.text\n",
        "y = yelp_best_worst.stars.map({1:0, 5:1})\n",
        "y = yelp_best_worst.stars.map({1:0, 5:1})\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
        "X_train.to_csv(train_file_path, header=False, index=False, columns=['text'])\n",
        "X_test.to_csv(test_file_path, header=False, index=False, columns=['text'])"
      ],
      "metadata": {
        "id": "MdhWQqKZkTaR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_corpus(fname, tokens_only=False):\n",
        "    with smart_open.open(fname, encoding=\"iso-8859-1\") as f:\n",
        "        for i, line in enumerate(f):\n",
        "            tokens = gensim.utils.simple_preprocess(line)\n",
        "            if tokens_only:\n",
        "                yield tokens\n",
        "            else:\n",
        "                # For training data, add tags\n",
        "                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])"
      ],
      "metadata": {
        "id": "GghYGYNrkeT-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_corpus = list(read_corpus(train_file_path))[:vocabulary_size_to_use]\n",
        "test_corpus = list(read_corpus(test_file_path, tokens_only=True))"
      ],
      "metadata": {
        "id": "41pIWjw5mI0R"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_corpus[:2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fg-6ZGbumYD4",
        "outputId": "1775ef6d-29b7-4ee9-bfd0-5e9889e28914"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TaggedDocument(words=['if', 'could', 'give', 'it', 'more', 'than', 'would', 'sweet', 'pea', 'and', 'live', 'down', 'the', 'street', 'literally', 'down', 'the', 'street', 'from', 'this', 'bar', 'we', 'waited', 'for', 'it', 'to', 'open', 'for', 'what', 'seemed', 'like', 'decades', 'praying', 'that', 'this', 'was', 'going', 'to', 'be', 'the', 'type', 'of', 'place', 'that', 'could', 'become', 'our', 'local', 'it', 'has', 'exceeded', 'our', 'expectations', 'the', 'atmosphere', 'is', 'amazing', 'the', 'drinks', 'are', 'amazing', 'every', 'last', 'one', 'of', 'them', 'but', 'the', 'margaritas', 'are', 'the', 'best', 've', 'ever', 'had', 'they', 'tasted', 'like', 'fresh', 'squeeze', 'of', 'sunshine', 'that', 'makes', 'me', 'happy', 'inside', 'margarita', 'mondays', 'margs', 'and', 'free', 'food', 'happy', 'hours', 'are', 'amazing', 'new', 'year', 'eve', 'last', 'year', 'was', 'amazing', 'the', 'year', 'anniversary', 'party', 'was', 'amazing', 'but', 'most', 'of', 'all', 'the', 'owner', 'and', 'staff', 'are', 'some', 'of', 'the', 'coolest', 'peeps', 'that', 'you', 'll', 'ever', 'meet', 'go', 'here', 'you', 'will', 'love', 'it'], tags=[0]), TaggedDocument(words=['we', 'had', 'fantastic', 'experience', 'here', 'we', 'went', 'on', 'thursday', 'evening', 'and', 'with', 'the', 'misters', 'on', 'it', 'was', 'still', 'very', 'pleasant', 'sitting', 'outside', 'even', 'in', 'june', 'the', 'wine', 'list', 'was', 'extremely', 'affordable', 'most', 'between', 'and', 'for', 'scottsdale', 'this', 'is', 'steal', 'we', 'shared', 'an', 'appetizer', 'and', 'main', 'entree', 'the', 'appetizer', 'was', 'delish', 'grilled', 'bread', 'perfectly', 'grilled', 'not', 'so', 'hard', 'that', 'it', 'hurts', 'your', 'gums', 'with', 'three', 'spreads', 'an', 'amazing', 'goat', 'cheese', 'and', 'marscapone', 'eggplant', 'and', 'hummus', 'also', 'they', 'serve', 'house', 'bread', 'with', 'great', 'sun', 'dried', 'tomato', 'butter', 'for', 'our', 'entree', 'we', 'shared', 'the', 'fish', 'special', 'which', 'was', 'sea', 'bass', 'with', 'artichokes', 'fingerling', 'potatoes', 'and', 'spinach', 'fantastic', 'the', 'service', 'was', 'also', 'great'], tags=[1])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = gensim.models.doc2vec.Doc2Vec(vector_size=embedding_dim, min_count=2, epochs=epochs, workers=5)\n",
        "model.build_vocab(train_corpus)"
      ],
      "metadata": {
        "id": "R95ZH6okmZ3Z"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)\n"
      ],
      "metadata": {
        "id": "-1Y0gLAumcEJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector = model.infer_vector(['only', 'you', 'can', 'prevent', 'forest', 'fires'])\n",
        "print(vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XLPfSgXmdYr",
        "outputId": "576a1bee-5c19-45c1-bd18-25da24209c7d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.02762986  0.00179712  0.03048734 -0.00375619 -0.03567026 -0.05924828\n",
            " -0.00979371  0.05149005 -0.05577854 -0.00663567 -0.01950982 -0.01442671\n",
            "  0.02828592  0.04166871  0.03524429 -0.07006898  0.02940768 -0.05654595\n",
            " -0.02355556 -0.02870545  0.02540269 -0.02266831 -0.0315986   0.01148102\n",
            " -0.04188496 -0.10340449  0.01125128  0.03223917  0.06352893 -0.00545531\n",
            "  0.070298   -0.05531643 -0.0072738   0.01125406 -0.03984931  0.05630789\n",
            "  0.05494026  0.05946151 -0.02652008 -0.06166969  0.03374788 -0.01944711\n",
            " -0.01121592  0.03518479 -0.05244188 -0.01358799 -0.04486623 -0.04464933\n",
            "  0.00853691 -0.02403549  0.00398715 -0.03169059  0.02048805 -0.01051473\n",
            " -0.00430318 -0.03759081  0.01480608  0.0246211  -0.00719381  0.0687056\n",
            " -0.02043215 -0.06467283  0.0650305   0.01485862 -0.06586582 -0.04737824\n",
            " -0.00392825 -0.0202585  -0.0050929  -0.0207573   0.04117596  0.00476713\n",
            "  0.02556793 -0.00289785  0.03210641 -0.052872   -0.00215181 -0.00910484\n",
            "  0.00828335 -0.05540834  0.0420768  -0.03149442 -0.02498448 -0.02399146\n",
            "  0.00485324  0.0608255  -0.00587604 -0.03474145  0.02557047 -0.00219417\n",
            "  0.01982306  0.00903288  0.0123122   0.00845557 -0.0248062   0.00682183\n",
            " -0.01812285  0.01941864  0.02528865 -0.01542138]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick a random document from the train corpus and infer a vector from the model\n",
        "doc_id = random.randint(0, len(test_corpus) - 1)\n",
        "inferred_vector = model.infer_vector(test_corpus[doc_id])\n",
        "sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
        "\n",
        "# Compare and print the most similar documents from the train corpus\n",
        "print('Test Document ({}): «{}»\\n'.format(doc_id, ' '.join(test_corpus[doc_id])))\n",
        "print(u'MOST SIMILAR %s: «%s»\\n' % (sims[0], ' '.join(train_corpus[sims[0][0]].words)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksHb8OJUmeVo",
        "outputId": "5c246557-4cdd-425a-9ad4-58dd7d79297f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Document (1531): «do agree with couple of the reviewers who mentioned salt there were couple of dishes that had just tad too much however think that was not due to mistake of the chef believe it is just because they use cured meats in lot of their dishes another reviewer mentioned bad service but we did not experience that at all our server was extremely warm and friendly she was very knowledgeable on the food and could answer any questions we had for her she also took the time for each course to explain each dish and in my case the wine and why they went together only one time did my wine not come out at the same time with the food course and in that case our server apologized immediately do agree with some of the reviewers that the service is very slow however believe that this is intentional they have created very cozy and comfortable environment and they want you to linger and enjoy yourself with the farmer feast in particular it took us almost hours start to finish but enjoyed every minute of it it was nice to have time in between courses to sit and talk and relax the spacing also kept us from feeling too full by the end it is six courses after all or from letting the flavors from one dish influence the next was able to enjoy each course separately and independently with its own unique wine it was pure food heaven this is not the type of place where you would stop in for meal before show or event when you come here this should be your only destination for the night and it is such great experience that it will be enough we truly had fantastic night here»\n",
            "\n",
            "MOST SIMILAR (10310, 0.6335013508796692): «first off would like to punch the dip shit on the food network who said this was the best chicken he ever ate yeah the place is filthy but how they operate their business is redicolus service sucks minute wait for the food sucks waiting minutes from the first entree being dropped off until the last person luckily receives their food sucks being told on the th minute of hour wait for your food that they are out of your side dishes sucks spending my hard earned money at place that is ass backwards in any kind of business sense sucks at first our group thought it was joke then the reverse racism theory was brought up then we noticed that every table was experiencing the same lack of service black white purple orange they just sucked»\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0DiA0qzWmjt9"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lhBB28lUooO1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}