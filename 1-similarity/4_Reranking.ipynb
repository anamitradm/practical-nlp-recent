{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "# Lab 4\n",
    "\n",
    "## Reranking on Similarity\n",
    "\n",
    "In this notebook we will rerank the results based on simiarity with some sample reviews in the Yelp dataset, reusing the Doc2Vec model from the previous lab.\n",
    "\n",
    "You can run this lab both locally or in Colab.\n",
    "\n",
    "- To run in Colab just go to `https://colab.research.google.com`, sign-in and you upload this notebook. Colab has GPU access for free.\n",
    "- To run locally just run `jupyter notebook` and access the notebook in this lab. You would need to first install the requirements in `requirements.txt`\n",
    "\n",
    "Follow the instructions. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bv7ld82dP5fX",
    "outputId": "b13133a6-de25-4ae4-e276-056431ee480d"
   },
   "outputs": [],
   "source": [
    "!pip install textblob 'keras-nlp' 'keras-preprocessing'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fTnc0QXRp2my"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rJw0Zi-SqyPD",
    "outputId": "08f9041f-483a-4f1b-a99c-84bf6ad506f6"
   },
   "outputs": [],
   "source": [
    "%%writefile get_data.sh\n",
    "\n",
    "if [ ! -f yelp.csv ]; then\n",
    "  wget -O yelp.csv https://www.dropbox.com/s/xds4lua69b7okw8/yelp.csv?dl=0\n",
    "fi\n",
    "if [ ! -f doc2vec_yelp_model ]; then\n",
    "  wget -O doc2vec_yelp_model https://www.dropbox.com/s/bibu9bashb0cd68/doc2vec_yelp_model?dl=0\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2CqfNhYbq2Rc",
    "outputId": "5da69f98-5662-4b93-a81c-9ce452d40cd1"
   },
   "outputs": [],
   "source": [
    "!bash get_data.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9UImHGys0W-"
   },
   "outputs": [],
   "source": [
    "model = None # Load the Doc2Vec model from the file we downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q6UevuIjrL3y"
   },
   "outputs": [],
   "source": [
    "query = 'Best french restaurant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dRrYUm0Srl3L"
   },
   "outputs": [],
   "source": [
    "# Use the same simple_preprocess from the last lab 4 to tokenize the query\n",
    "tokenized_query = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "orpGr66Drn0i",
    "outputId": "968e70da-ab6a-4e22-b9e6-98e1dcade1f0"
   },
   "outputs": [],
   "source": [
    "inferred_vector = model.infer_vector(tokenized_query)\n",
    "print(inferred_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kt_8M1DErpBE"
   },
   "outputs": [],
   "source": [
    "path = './yelp.csv'\n",
    "yelp = pd.read_csv(path)\n",
    "# Create a new DataFrame that only contains the 5-star and 1-star reviews.\n",
    "yelp_best_worst = yelp[(yelp.stars==5) | (yelp.stars==1)]\n",
    "sample_reviews = yelp_best_worst.text.sample(n=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6I6iCs5hr-un"
   },
   "outputs": [],
   "source": [
    "similarities = []\n",
    "for review in sample_reviews:\n",
    "    similarity = 0 # Find the similarity between the query and the review using gensim\n",
    "    similarities.append(similarity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, what we have done is having a query term, then finding the similarity between the query and the reviews.\n",
    "\n",
    "The idea behind the algorithm would be to reorder the results based on the similarity score, not on BM25. Let's see which one is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AExGb24QsfTm"
   },
   "outputs": [],
   "source": [
    "# Create a dataframe that has as columns the sample reviews and the similarity with the query\n",
    "reviews_with_similarities = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kAPC7StcspBr"
   },
   "outputs": [],
   "source": [
    "a = None # Sort the df_results by similarity column in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Xg8RZObtQQ0",
    "outputId": "100845ac-83ef-4333-e296-d2ff2d98e87b"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(f'Most similar document after reranking within retrieved results has description: \\n\\n{a[\"review\"].iloc[0]}\\n\\nWith similarity: {a[\"similarity\"].iloc[0]}\\n\\n---------\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sa-L-YPYR26w"
   },
   "outputs": [],
   "source": [
    "print(f'Most similar document before reranking within retrieved results has description: \\n\\n{reviews_with_similarities[\"review\"].iloc[0]}\\n\\nWith similarity: {reviews_with_similarities[\"similarity\"].iloc[0]}\\n\\n---------\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of documents that surpass 0.5 similarity threshold: {len(a[a[\"similarity\"] >= 0.5])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is remarkable how using DBOW the most similar result understood the need for good prices and good food (which can be said characterizes french food). On the other hand the least similar result is a sports bar, which seems about right as well!.\n",
    "\n",
    "It is not a perfect method, but a very good indication. A good idea is to have something like this **between** the raw results (thousands), filter them by similarity (hundreds) and then have a learning to rank recommender (dozens).\n",
    "\n",
    "Tensorflow has opensources TF Recommenders which is great to plug in as an algorithm **after** these results. But this alone would work just fine.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMtUYeizXsth7Ia5GcX7Ik3",
   "collapsed_sections": [],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}