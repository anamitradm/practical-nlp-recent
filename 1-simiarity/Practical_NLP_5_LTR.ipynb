{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/axel-sirota/practical-nlp/blob/main/1-simiarity/Practical_NLP_5_LTR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bb6KgZcudKT",
        "outputId": "6a29417f-601e-45eb-909e-7245e035af69"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Oct 14 14:52:54 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'gensim==4.2.0'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVyuAnDLyvBE",
        "outputId": "c5db7809-56f7-4e0b-f2c9-e08910a9c3f4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gensim==4.2.0\n",
            "  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.2.0) (5.2.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim==4.2.0) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.2.0) (1.7.3)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "aLsDbhgoqZyt"
      },
      "outputs": [],
      "source": [
        "import multiprocessing\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras import layers, activations, losses, Model, Input\n",
        "from keras.layers import Dense, Embedding, Lambda\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from textblob import TextBlob, Word\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.initializers import Constant\n",
        "from tensorflow.nn import leaky_relu\n",
        "from tensorflow.keras.utils import plot_model, Progbar\n",
        "from gensim.models import Doc2Vec\n",
        "import gensim\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "import gensim\n",
        "import warnings\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from itertools import combinations\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "TRACE = False\n",
        "embedding_dim = 100\n",
        "epochs=50\n",
        "batch_size = 50\n",
        "sample_queries = 20\n",
        "sample_results_dataset = 100\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RWTlcgNpqZyv"
      },
      "outputs": [],
      "source": [
        "def set_seeds_and_trace():\n",
        "  os.environ['PYTHONHASHSEED'] = '0'\n",
        "  np.random.seed(42)\n",
        "  tf.random.set_seed(42)\n",
        "  random.seed(42)\n",
        "  if TRACE:\n",
        "    tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "def set_session_with_gpus_and_cores():\n",
        "  cores = multiprocessing.cpu_count()\n",
        "  gpus = len(tf.config.list_physical_devices('GPU'))\n",
        "  config = tf.compat.v1.ConfigProto( device_count = {'GPU': gpus  , 'CPU': cores} , intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "  sess = tf.compat.v1.Session(config=config) \n",
        "  K.set_session(sess)\n",
        "\n",
        "set_seeds_and_trace()\n",
        "set_session_with_gpus_and_cores()\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "TPLKmvNFqZyw"
      },
      "source": [
        "The idea behind RankNet is to model the **joint probability** that `document i` comes before `document j` as the following:\n",
        "\n",
        "$P_{ij} = 1$ if $s_i > s_j$\n",
        "$P_{ij} = 0.5$ if $s_i = s_j$\n",
        "$P_{ij} = 0$ if $s_i < s_j$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Ma7YD0WTqZyy"
      },
      "source": [
        "So for *every pair of inputs* we will calculate both outputs, substract them, pass a logistic function to model the probability:\n",
        "\n",
        "<img src=\"./ranknet.png\">"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile get_data.sh\n",
        "\n",
        "if [ ! -f yelp.csv ]; then\n",
        "  wget -O yelp.csv https://www.dropbox.com/s/xds4lua69b7okw8/yelp.csv?dl=0\n",
        "fi\n",
        "if [ ! -f doc2vec_yelp_model ]; then\n",
        "  wget -O doc2vec_yelp_model https://www.dropbox.com/s/bibu9bashb0cd68/doc2vec_yelp_model?dl=0\n",
        "fi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVRPlgP2wcpc",
        "outputId": "2552b401-8ecd-42d3-95fb-71bece257cea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing get_data.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash get_data.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_HceAKmwc3m",
        "outputId": "d28aa654-5009-40a5-957b-3b1719c76e8b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-14 14:53:08--  https://www.dropbox.com/s/xds4lua69b7okw8/yelp.csv?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.6.18, 2620:100:6019:18::a27d:412\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.6.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/xds4lua69b7okw8/yelp.csv [following]\n",
            "--2022-10-14 14:53:10--  https://www.dropbox.com/s/raw/xds4lua69b7okw8/yelp.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc9466b1dac10912a34905555252.dl.dropboxusercontent.com/cd/0/inline/BuyDpwow73MjDtN-JBOdxmCy5ea5JB9P-foL-To_Voqzeu8OMqWMCEPDRiayxmHKNmn02LgUpuU56RkTVejQacZk6U5nggXwgtOvXShpow-iS_sJHgfMB_dcQVjL5bnWlMoojUbxUV6A6pT-eYEPpX9dwCJVq-xnBCI_lPXB6LSI9w/file# [following]\n",
            "--2022-10-14 14:53:10--  https://uc9466b1dac10912a34905555252.dl.dropboxusercontent.com/cd/0/inline/BuyDpwow73MjDtN-JBOdxmCy5ea5JB9P-foL-To_Voqzeu8OMqWMCEPDRiayxmHKNmn02LgUpuU56RkTVejQacZk6U5nggXwgtOvXShpow-iS_sJHgfMB_dcQVjL5bnWlMoojUbxUV6A6pT-eYEPpX9dwCJVq-xnBCI_lPXB6LSI9w/file\n",
            "Resolving uc9466b1dac10912a34905555252.dl.dropboxusercontent.com (uc9466b1dac10912a34905555252.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:6019:15::a27d:40f\n",
            "Connecting to uc9466b1dac10912a34905555252.dl.dropboxusercontent.com (uc9466b1dac10912a34905555252.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8091185 (7.7M) [text/plain]\n",
            "Saving to: ‘yelp.csv’\n",
            "\n",
            "yelp.csv            100%[===================>]   7.72M  22.4MB/s    in 0.3s    \n",
            "\n",
            "2022-10-14 14:53:11 (22.4 MB/s) - ‘yelp.csv’ saved [8091185/8091185]\n",
            "\n",
            "--2022-10-14 14:53:11--  https://www.dropbox.com/s/bibu9bashb0cd68/doc2vec_yelp_model?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.6.18, 2620:100:6019:18::a27d:412\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.6.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/bibu9bashb0cd68/doc2vec_yelp_model [following]\n",
            "--2022-10-14 14:53:11--  https://www.dropbox.com/s/raw/bibu9bashb0cd68/doc2vec_yelp_model\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucf0f5d2c601d3c6f993744f3e16.dl.dropboxusercontent.com/cd/0/inline/BuzvdgGCH6RvawrPNlHfokqDCX-dA6ZCSOMYt0M1yTGu9lsQBUkOa0LbutAUD-ZRkfZEHDHvT2HeSN3MQx-y_wFoLwwj9UvamOiVWXsAIw3h5oWJ6BVB20-nXV2_HKLg-omVzO07Lvclay5sQY3fWgrfo_47MN-1NhCRLt52NUj97g/file# [following]\n",
            "--2022-10-14 14:53:11--  https://ucf0f5d2c601d3c6f993744f3e16.dl.dropboxusercontent.com/cd/0/inline/BuzvdgGCH6RvawrPNlHfokqDCX-dA6ZCSOMYt0M1yTGu9lsQBUkOa0LbutAUD-ZRkfZEHDHvT2HeSN3MQx-y_wFoLwwj9UvamOiVWXsAIw3h5oWJ6BVB20-nXV2_HKLg-omVzO07Lvclay5sQY3fWgrfo_47MN-1NhCRLt52NUj97g/file\n",
            "Resolving ucf0f5d2c601d3c6f993744f3e16.dl.dropboxusercontent.com (ucf0f5d2c601d3c6f993744f3e16.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:6017:15::a27d:20f\n",
            "Connecting to ucf0f5d2c601d3c6f993744f3e16.dl.dropboxusercontent.com (ucf0f5d2c601d3c6f993744f3e16.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/Buw09eh-E63PqtlN1AZpPDhkVbwoqfHk83XQ5GTnMeGw8CaKGvt5d22beDLXAOXRPbtlDdAn5UgcTMtrcraeHXy3aPufXsRNW7jEnzaLYlpPdYRHYWkW8YZtqJxY2dwLnITsBp4QgcfxTaUGHIo3upeXOVpGUGRtnHYJStEXuf0hzCA9OLxfUpSXa2mOwEKyUnLnfSGfuGWcK-hYckkpOuoJV-oxQ7ZG-grn7ujW5TG_vPTc4bk76OcCkAWwjg33dGBtQn6EoN1vxwrStwAHthL-yf3H6-r20iz35LNZizf0xlGmIRaKejQjSlZEAJ3fUJE9i8vg3mg3L7r4vTJIXVpPDJhVu-DU9Yq7vwJgE6CAJvocVniE7z0DIo19pK6DQdCyrGgCTTUEEkurqRvMBG8RupUytyxrgyo7IaF9_Qa-mg/file [following]\n",
            "--2022-10-14 14:53:12--  https://ucf0f5d2c601d3c6f993744f3e16.dl.dropboxusercontent.com/cd/0/inline2/Buw09eh-E63PqtlN1AZpPDhkVbwoqfHk83XQ5GTnMeGw8CaKGvt5d22beDLXAOXRPbtlDdAn5UgcTMtrcraeHXy3aPufXsRNW7jEnzaLYlpPdYRHYWkW8YZtqJxY2dwLnITsBp4QgcfxTaUGHIo3upeXOVpGUGRtnHYJStEXuf0hzCA9OLxfUpSXa2mOwEKyUnLnfSGfuGWcK-hYckkpOuoJV-oxQ7ZG-grn7ujW5TG_vPTc4bk76OcCkAWwjg33dGBtQn6EoN1vxwrStwAHthL-yf3H6-r20iz35LNZizf0xlGmIRaKejQjSlZEAJ3fUJE9i8vg3mg3L7r4vTJIXVpPDJhVu-DU9Yq7vwJgE6CAJvocVniE7z0DIo19pK6DQdCyrGgCTTUEEkurqRvMBG8RupUytyxrgyo7IaF9_Qa-mg/file\n",
            "Reusing existing connection to ucf0f5d2c601d3c6f993744f3e16.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13243389 (13M) [application/octet-stream]\n",
            "Saving to: ‘doc2vec_yelp_model’\n",
            "\n",
            "doc2vec_yelp_model  100%[===================>]  12.63M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-10-14 14:53:13 (88.0 MB/s) - ‘doc2vec_yelp_model’ saved [13243389/13243389]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Doc2Vec.load(\"./doc2vec_yelp_model\")"
      ],
      "metadata": {
        "id": "Ec69pypxwc6Z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = './yelp.csv'\n",
        "yelp = pd.read_csv(path)\n",
        "train_set_reviews = yelp.sample(n=sample_results_dataset).reset_index(drop=True)\n",
        "queries = yelp.text.sample(n=sample_queries).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "mHwqq3Vdwc9k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6jiwvrQym49",
        "outputId": "156cb2d2-66e4-425f-c346-e7f6a8dd3056"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     I really try to like Old Town Scottsdale - and...\n",
              "1     (aka. SKETCHY TEMPE with BONNIE G, Part One of...\n",
              "2     Thought Saturday night would be busy at 6:00 P...\n",
              "3     I was actually really impressed, even though I...\n",
              "4     Pros:\\n1.  Excellent service.  Hell, it's damn...\n",
              "5     Treated with complete disrespect. Worst servic...\n",
              "6     I met up with a girlfriend at borders. This Bo...\n",
              "7     First time here and it was really good. I orde...\n",
              "8     I'm on a low carb diet right now, so I had to ...\n",
              "9     I got my nails done there last Thursday for th...\n",
              "10    I was referred to Jones Family Dentistry for a...\n",
              "11    Just went to this theater last night, and it w...\n",
              "12    The Harkins Camelview 5 gives Arizonans the un...\n",
              "13    Great new addition to the Old Town neighborhoo...\n",
              "14    What can I say that hasn't already been said a...\n",
              "15    This place is essentially a copy of the old Fa...\n",
              "16    I have been coming here since discovering them...\n",
              "17    Delicious barbecue, we had 4 meats platter tha...\n",
              "18    My favorite trail in South Mountain starts at ...\n",
              "19    Great product! I was on a mission to make home...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = np.zeros((len(queries), len(train_set_reviews), 100))\n",
        "scores = np.zeros((len(queries), len(train_set_reviews)))\n",
        "for q_ix, query in enumerate(queries):\n",
        "  for r_ix, review in enumerate(train_set_reviews):\n",
        "    try:\n",
        "        similarity = model.similarity_unseen_docs(doc_words1=list(gensim.utils.simple_preprocess(query)), doc_words2= list(gensim.utils.simple_preprocess(review)))\n",
        "    except KeyError:\n",
        "        similarity = 0\n",
        "    feature = model.infer_vector(list(gensim.utils.simple_preprocess(review)))\n",
        "    results[q_ix][r_ix] = feature\n",
        "    scores[q_ix][r_ix] = similarity\n"
      ],
      "metadata": {
        "id": "sz8kOxJRwdAm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# put data into pairs\n",
        "xi = []\n",
        "xj = []\n",
        "pij = []\n",
        "pair_id = []\n",
        "pair_query_id = []\n",
        "for q_ix, query in enumerate(queries):\n",
        "    for pair_idx in combinations(enumerate(results[q_ix]), 2):\n",
        "        pair_query_id.append(query)\n",
        "        pair_id.append(pair_idx)\n",
        "        ix_i, document_i = pair_idx[0]\n",
        "        ix_j, document_j = pair_idx[1]\n",
        "        xi.append(document_i)\n",
        "        xj.append(document_j)\n",
        "\n",
        "        if scores[q_ix][ix_i] == scores[q_ix][ix_j]:\n",
        "            _pij = 0.5\n",
        "        elif scores[q_ix][ix_i] > scores[q_ix][ix_j]:\n",
        "            _pij = 1\n",
        "        else:\n",
        "            _pij = 0\n",
        "        pij.append(_pij)\n",
        "\n",
        "xi = np.array(xi)\n",
        "xj = np.array(xj)\n",
        "pij = np.array(pij)\n",
        "pair_query_id = np.array(pair_query_id)\n",
        "del results\n",
        "del scores\n"
      ],
      "metadata": {
        "id": "WodU_Ep_zXzY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xi_train, xi_test, xj_train, xj_test, pij_train, pij_test, pair_id_train, pair_id_test = train_test_split(\n",
        "    xi, xj, pij, pair_id, test_size=0.2, stratify=pair_query_id)"
      ],
      "metadata": {
        "id": "5i-IcbTQzX19"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xi_train = tf.constant(xi_train)\n",
        "xi_test = tf.constant(xi_test)\n",
        "xj_train = tf.constant(xj_train)\n",
        "xj_test = tf.constant(xj_test)\n",
        "pij_train = tf.constant(pij_train)\n",
        "pij_test = tf.constant(pij_test)\n",
        "pair_id_train = pair_id_train\n",
        "pair_id_test = pair_id_test"
      ],
      "metadata": {
        "id": "NH_8rmrfzX4X"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "hP0hwcIxqZyz"
      },
      "outputs": [],
      "source": [
        "# model architecture\n",
        "class RankNet(Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.dense = [layers.Dense(16, activation=leaky_relu), layers.Dense(8, activation=leaky_relu)]\n",
        "        self.o = layers.Dense(1, activation='linear')\n",
        "        self.oi_minus_oj = layers.Subtract()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        xi, xj = inputs\n",
        "        densei = self.dense[0](xi)\n",
        "        densej = self.dense[0](xj)\n",
        "        for dense in self.dense[1:]:\n",
        "            densei = dense(densei)\n",
        "            densej = dense(densej)\n",
        "        oi = self.o(densei)\n",
        "        oj= self.o(densej)\n",
        "        oij = self.oi_minus_oj([oi, oj])\n",
        "        output = layers.Activation('sigmoid')(oij)\n",
        "        return output\n",
        "\n",
        "    def build_graph(self):\n",
        "        x = [Input(shape=(10)), Input(shape=(10))]\n",
        "        return Model(inputs=x, outputs=self.call(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIWp7ZNtqZy2",
        "outputId": "dee9126c-f11e-4a91-fbb4-a5d39d540b6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1584/1584 [==============================] - 5s 3ms/step - loss: 0.6233 - val_loss: 0.6161\n",
            "Epoch 2/50\n",
            "1584/1584 [==============================] - 5s 3ms/step - loss: 0.6152 - val_loss: 0.6130\n",
            "Epoch 3/50\n",
            "1584/1584 [==============================] - 5s 3ms/step - loss: 0.6116 - val_loss: 0.6095\n",
            "Epoch 4/50\n",
            "1584/1584 [==============================] - 5s 3ms/step - loss: 0.6080 - val_loss: 0.6051\n",
            "Epoch 5/50\n",
            "1584/1584 [==============================] - 5s 3ms/step - loss: 0.6043 - val_loss: 0.6034\n",
            "Epoch 6/50\n",
            "1584/1584 [==============================] - 5s 3ms/step - loss: 0.6031 - val_loss: 0.6029\n",
            "Epoch 7/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6025 - val_loss: 0.6023\n",
            "Epoch 8/50\n",
            "1584/1584 [==============================] - 6s 4ms/step - loss: 0.6021 - val_loss: 0.6020\n",
            "Epoch 9/50\n",
            "1584/1584 [==============================] - 5s 3ms/step - loss: 0.6019 - val_loss: 0.6020\n",
            "Epoch 10/50\n",
            "1584/1584 [==============================] - 5s 3ms/step - loss: 0.6018 - val_loss: 0.6018\n",
            "Epoch 11/50\n",
            "1584/1584 [==============================] - 5s 3ms/step - loss: 0.6016 - val_loss: 0.6018\n",
            "Epoch 12/50\n",
            "1584/1584 [==============================] - 5s 3ms/step - loss: 0.6015 - val_loss: 0.6017\n",
            "Epoch 13/50\n",
            "1584/1584 [==============================] - 5s 3ms/step - loss: 0.6014 - val_loss: 0.6016\n",
            "Epoch 14/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6014 - val_loss: 0.6015\n",
            "Epoch 15/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6013 - val_loss: 0.6015\n",
            "Epoch 16/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6013 - val_loss: 0.6017\n",
            "Epoch 17/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6012 - val_loss: 0.6014\n",
            "Epoch 18/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6012 - val_loss: 0.6020\n",
            "Epoch 19/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6013 - val_loss: 0.6014\n",
            "Epoch 20/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6011 - val_loss: 0.6017\n",
            "Epoch 21/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6011 - val_loss: 0.6015\n",
            "Epoch 22/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6010 - val_loss: 0.6014\n",
            "Epoch 23/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6010 - val_loss: 0.6018\n",
            "Epoch 24/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6010 - val_loss: 0.6016\n",
            "Epoch 25/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6009 - val_loss: 0.6016\n",
            "Epoch 26/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6009 - val_loss: 0.6013\n",
            "Epoch 27/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6008 - val_loss: 0.6016\n",
            "Epoch 28/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6009 - val_loss: 0.6013\n",
            "Epoch 29/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6008 - val_loss: 0.6012\n",
            "Epoch 30/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6007 - val_loss: 0.6017\n",
            "Epoch 31/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6007 - val_loss: 0.6015\n",
            "Epoch 32/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6007 - val_loss: 0.6019\n",
            "Epoch 33/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6007 - val_loss: 0.6011\n",
            "Epoch 34/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6006 - val_loss: 0.6016\n",
            "Epoch 35/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6006 - val_loss: 0.6011\n",
            "Epoch 36/50\n",
            "1584/1584 [==============================] - 6s 3ms/step - loss: 0.6006 - val_loss: 0.6012\n",
            "Epoch 37/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6007 - val_loss: 0.6013\n",
            "Epoch 38/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6006 - val_loss: 0.6018\n",
            "Epoch 39/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6006 - val_loss: 0.6011\n",
            "Epoch 40/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6005 - val_loss: 0.6012\n",
            "Epoch 41/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6005 - val_loss: 0.6014\n",
            "Epoch 42/50\n",
            "1584/1584 [==============================] - 5s 3ms/step - loss: 0.6006 - val_loss: 0.6013\n",
            "Epoch 43/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6005 - val_loss: 0.6013\n",
            "Epoch 44/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6005 - val_loss: 0.6011\n",
            "Epoch 45/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6005 - val_loss: 0.6010\n",
            "Epoch 46/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6005 - val_loss: 0.6018\n",
            "Epoch 47/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6004 - val_loss: 0.6015\n",
            "Epoch 48/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6005 - val_loss: 0.6014\n",
            "Epoch 49/50\n",
            "1584/1584 [==============================] - 4s 3ms/step - loss: 0.6005 - val_loss: 0.6014\n",
            "Epoch 50/50\n",
            "1584/1584 [==============================] - 5s 3ms/step - loss: 0.6004 - val_loss: 0.6011\n"
          ]
        }
      ],
      "source": [
        "# train model using compile and fit\n",
        "ranknet = RankNet()\n",
        "ranknet.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "history = ranknet.fit([xi_train, xj_train], pij_train, epochs=epochs, batch_size=batch_size, validation_data=([xi_test, xj_test], pij_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ranknet.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nElcBh2dB3If",
        "outputId": "dcd481f2-7d04-4c06-97c2-d98b406f02cf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"rank_net_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            multiple                  1616      \n",
            "                                                                 \n",
            " dense_13 (Dense)            multiple                  136       \n",
            "                                                                 \n",
            " dense_14 (Dense)            multiple                  9         \n",
            "                                                                 \n",
            " subtract_4 (Subtract)       multiple                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,761\n",
            "Trainable params: 1,761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "MQOC3drYqZy2",
        "outputId": "b8678027-abd7-4d58-c29b-c43816aa0a8f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# function for plotting loss\n",
        "def plot_metrics(train_metric, val_metric=None, metric_name=None, title=None, ylim=5):\n",
        "    plt.title(title)\n",
        "    plt.ylim(0,ylim)\n",
        "    plt.plot(train_metric,color='blue',label=metric_name)\n",
        "    if val_metric is not None: plt.plot(val_metric,color='green',label='val_' + metric_name)\n",
        "    plt.legend(loc=\"upper right\")\n",
        "\n",
        "# plot loss history\n",
        "plot_metrics(history.history['loss'], history.history['val_loss'], \"Loss\", \"Loss\", ylim=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "GY6qE2UpqZy3"
      },
      "outputs": [],
      "source": [
        "new_doci = tf.constant([model.infer_vector(list(gensim.utils.simple_preprocess('This was the best french place in the world')))])\n",
        "new_docj = tf.constant([model.infer_vector(list(gensim.utils.simple_preprocess('Wouldnt come back ever again')))])\n",
        "inputs = tf.constant(np.array([new_doci, new_docj]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECeXJCRNqZy3",
        "outputId": "98ab7c65-ec7f-49be-e870-5d962c6fee0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "inputs[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8maoyFfdBxru",
        "outputId": "f88359ce-8b56-4ed3-cc97-8dff9ca4287c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 100), dtype=float32, numpy=\n",
              "array([[-0.01484802, -0.01572138, -0.02401376,  0.00360791,  0.00858026,\n",
              "        -0.03434326, -0.00303746,  0.06181582, -0.04121519,  0.0013705 ,\n",
              "         0.01736436, -0.04558966, -0.02606856,  0.05313838,  0.02748182,\n",
              "        -0.01010834, -0.02102506, -0.00101264, -0.01293747, -0.05078515,\n",
              "         0.02430892,  0.0475943 ,  0.03893576,  0.00232368, -0.02713238,\n",
              "         0.00366601, -0.04957069, -0.02590737, -0.04251442,  0.00635415,\n",
              "         0.04378794, -0.02500792,  0.00234092, -0.04221196,  0.00285723,\n",
              "         0.02950317, -0.00236419,  0.02041181, -0.00893302, -0.04340103,\n",
              "        -0.01211206, -0.03778659, -0.01399105, -0.00432926,  0.01575397,\n",
              "         0.02155238, -0.03246578,  0.00781459,  0.00284644,  0.02879379,\n",
              "         0.02593884, -0.0617569 , -0.01840962, -0.03232995, -0.02742082,\n",
              "         0.0070127 , -0.00037809, -0.03478675, -0.0211691 ,  0.00332741,\n",
              "         0.00099683,  0.00594685,  0.02467218,  0.0001332 , -0.03985986,\n",
              "         0.07571837, -0.00484213,  0.03504305, -0.01990346,  0.01647221,\n",
              "        -0.0085393 ,  0.01806804,  0.01470219, -0.02174825,  0.05860591,\n",
              "         0.0308094 , -0.03160214,  0.02151247, -0.02211355, -0.01345507,\n",
              "        -0.01678342,  0.01310742, -0.01323752,  0.02666158,  0.01100211,\n",
              "         0.00013506,  0.01464743,  0.02760028,  0.0087951 ,  0.01802598,\n",
              "         0.04742936,  0.02987275, -0.00152967,  0.03518342,  0.04136901,\n",
              "         0.03048588, -0.01114712,  0.01526266, -0.0186551 ,  0.00825544]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ranknet(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOdqELijBybJ",
        "outputId": "26ffcd99-a129-4600-85fd-f18716a12c5a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k9Sp4l4AByrh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}